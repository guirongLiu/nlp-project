{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "import pandas as pd\n",
    "\n",
    "# data set up\n",
    "df = pd.read_csv('cleaned_data.csv', encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature 1: questions without stopwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(sent):\n",
    "    tokens=[token.lower() for token in nltk.word_tokenize(sent)]\n",
    "    stopwords_list=list(stopwords.words(\"english\"))\n",
    "    return \" \".join([token for token in tokens if token not in stopwords_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature 2: character length ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def character_length_ratio(sent1,sent2):\n",
    "    \"\"\"\n",
    "    params: two question sentences sent1 and sent2\n",
    "    return: ratio\n",
    "    \"\"\"\n",
    "    return sent1/max(1,sent2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature 3: number of same words or synonyms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method get_number_of_same_words(sent1, sent2) can return the number of same or synonyms words according to the wordnet.\n",
    "Forexaple, we have sent1-\"cat dog is?\" and sent2-\"good cat equals dog.\". This method will return 3, since it consider \"cat\" is \"cat\", \"dog\" is \"dog\", and \"equals\" is synonym of \"is\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_synonyms(word):\n",
    "    \"\"\"\n",
    "    params: word\n",
    "    return: list of synonyms of this word\n",
    "    \"\"\"\n",
    "    synonyms=[]\n",
    "    synsets=wn.synsets(word)\n",
    "    if synsets:\n",
    "        for synset in synsets:\n",
    "            for lemma in synset.lemmas():\n",
    "                synonyms.append(lemma.name())\n",
    "    return list(set(synonyms))\n",
    "\n",
    "def get_synonyms_set(sent):\n",
    "    tokens=nltk.word_tokenize(sent)\n",
    "    syn=[tokens]\n",
    "    for token in tokens:\n",
    "        if get_synonyms(token):\n",
    "            syn.append(get_synonyms(token))\n",
    "    return set([y for x in syn for y in x])\n",
    "\n",
    "def get_number_of_same_words(sent1,sent2):\n",
    "    count=0\n",
    "    syn_set_sent1=get_synonyms_set(sent1)\n",
    "    tokens=nltk.word_tokenize(sent2)\n",
    "    for token in tokens:\n",
    "        syn=get_synonyms(token)+[token]\n",
    "        for s in syn:\n",
    "            if s in syn_set_sent1:\n",
    "                count+=1\n",
    "                break\n",
    "    return count\n",
    "get_number_of_same_words(\"cat dogs is?\",\"good cat equals dog.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature 4: SOW model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this model, we ignore the order of text words, grammar and syntax, but only record whether a word appears in the text. To be more specific, we have a set, which has words that is in corpus, and we mark the length of the set as  V. We also mark V as the length of the word vector. So for each word, the value of the word at the corresponding position is 1, and others remain 0. For example, we have a dictionary set (“this”,”cat”,”dog”,”wants”,”play”,”to”,”do”,the”,”house”) and we have a text “This cat wants to play”. Therefore, the word vector is [1,1,0,1,1,1,0,0,0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dictionary_set():\n",
    "    \"\"\"\n",
    "    :return: set of tokens\n",
    "    \"\"\"\n",
    "    questions_set = set(df['question1']).union(df['question2'])\n",
    "    words_set = set()\n",
    "    for q in questions_set:\n",
    "        tokens = nltk.word_tokenize(q)\n",
    "        for token in tokens:\n",
    "            words_set.add(token)\n",
    "    return list(words_set)\n",
    "\n",
    "\n",
    "def get_sow_vector(sent):\n",
    "    dict_list=list(get_dictionary_set())\n",
    "    tokens=nltk.word_tokenize(sent)\n",
    "    vector=[0]*len(dict_list)\n",
    "    for token in tokens:\n",
    "        if token in dict_list:\n",
    "            index=dict_list.index[token]\n",
    "            if vector[index]==0:\n",
    "                vector[index]=1\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature 5: BOW model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BOW model\n",
    "This model is similar with SOW, but we also consider the occurrence of each word. For example, we have a dictionary set (“This”,”cat”,”and”,”that”,”dog”,”want”,”play”,”to”,”do”,the”,”house”) and we have a text “This cat and that cat want to play”, the word vector is [1,2,1,1,0,1,1,1,0,0,0].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bow_vector(sent):\n",
    "    dict_list=list(get_dictionary_set())\n",
    "    tokens=nltk.word_tokenize(sent)\n",
    "    vector=[0]*len(dict_list)\n",
    "    for token in tokens:\n",
    "        if token in dict_list:\n",
    "            index=dict_list.index[token]\n",
    "            vector[index]+=1\n",
    "    return vector\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature 6 : Syntatic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def syntatic_features(sent):\n",
    "    tokens=nltk.word_tokenize(sent)\n",
    "    tags = nltk.pos_tag(tokens)\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering Main Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extract(sent1,sent2):\n",
    "    \"\"\"\n",
    "    :param sent: sent of question as a string\n",
    "    :return: dictionary-keys are names of features, values are features\n",
    "    \"\"\"\n",
    "    dict={}\n",
    "    dict[\"remove_stopwords\"]=remove_stopwords(sent1)\n",
    "    dict[\"character_length_ratio\"]=character_length_ratio(sent1,sent2)\n",
    "    dict[\"syntatic_features\"]=syntatic_features(sent1)\n",
    "    dict[\"get_number_of_same_words\"]=get_number_of_same_words(sent1,sent2)\n",
    "    dict[\"bow vector\"]=get_bow_vector(sent1)\n",
    "    dict[\"sow vector\"]=get_sow_vector(sent1)\n",
    "    return dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
